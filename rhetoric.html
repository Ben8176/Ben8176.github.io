<!doctype html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>Rhetoric - AI Interview Prep</title>
    <link
      href="https://cdn.jsdelivr.net/npm/tailwindcss@2.2.19/dist/tailwind.min.css"
      rel="stylesheet"
    />
    <link rel="stylesheet" type="text/css" href="main.css" />
  </head>
  <body class="bg-gray-100">

    <!-- Navigation -->
    <nav class="bg-white p-4 shadow menu">
      <div class="container mx-auto">
        <a href="index.html" class="text-xl font-semibold">bengarofalo.com</a>
        <div class="float-right">
          <a href="index.html" class="ml-4 text-gray-700">Home</a>
          <a href="#" class="ml-4 text-gray-700">Cool Links</a>
        </div>
      </div>
    </nav>

    <div class="flex flex-col items-center mb-16 mt-16 mx-auto max-w-5xl">
            <h1 class="text-3xl">Rhetoric - Tone and Content Analysis with AI</h1>
            <br />

          <picture>
                <source type="image/webp" srcset="pics/rhetoricdemo.webp">
                <source type="image/png" srcset="pics/rhetoricdemo.png">
                <img src="pics/rhetoricdemo.png" class="">
          </picture>
          
        <p class="mt-4 mb-4">
          Rhetoric is an AI interview prep website that I built with my team during Calhacks 2023, where we stayed up for 48 hours
          learning and building our app. We started with a completely different project in mind, but the idea for an AI interview prep tool kind of bubbled up after we learned about Hume.ai's expression and tone analysis API. 
          
          <br/>
          <br/>

          With Rhetoric, the user records a video of themselves responding to an interview question randomly selected from a question bank. The response is then transcribed to text with OpenAI's Whisper API and analyzed using Hume.ai's emotional and tonal AI models to see whether your response was confident, nervous, arrogant etc. The transcribed text is sent to the LLaMA 13b LLM hosted with Together.ai, where it is prompted to give the user constructive feedback on the content of what they said. Finally, the results from the tonal and content analysis are presented to the user with an intuitive UI.

          <br/>
          <br/>
          Made with Flask, Node.js, with APIs from OpenAI, ElevenLabs, Hume.ai, and Together.ai
          <br/>
          <br/>
          The following diagram gives an overview of the app:
        </p>
        <br/>

        <picture>
                <source type="image/webp" srcset="pics/rhetoric_blocks.webp">
                <source type="image/png" srcset="pics/rhetoricdemo.png">
                <img src="pics/rhetoricdemo.png" class="">
        </picture>

    </div>
  </body>
</html>

